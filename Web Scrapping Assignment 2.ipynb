{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe665cb",
   "metadata": {},
   "source": [
    "**Q1**: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d010f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\1201994504.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "# Specify the path to the manually downloaded ChromeDriver executable\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Step 1: Open the webpage\n",
    "url = \"https://www.shine.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for a few seconds\n",
    "time.sleep(4)\n",
    "\n",
    "# Handle popup if present\n",
    "try:\n",
    "    popup = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".modal_modalWrapper__DZCQo\")))\n",
    "    close_button = popup.find_element(By.CSS_SELECTOR, \".btn-close\")\n",
    "    close_button.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "search_input = driver.find_element(By.CLASS_NAME, \"searchBarInput\")\n",
    "driver.execute_script(\"arguments[0].click();\", search_input)\n",
    "time.sleep(3)\n",
    "search_input = driver.find_element(By.ID, \"id_q\")\n",
    "driver.execute_script(\"arguments[0].value = 'Data Analyst';\", search_input)\n",
    "\n",
    "# Use JavaScript to input \"Bangalore\" into the location field\n",
    "location_element = driver.find_element(By.ID, 'id_loc')\n",
    "driver.execute_script(\"arguments[0].value = 'Bangalore';\", location_element)\n",
    "\n",
    "experience_input = driver.find_element(By.ID, \"id_exp\")\n",
    "\n",
    "# Input the desired experience value (e.g., \"2 years\")\n",
    "experience_input.send_keys(\" 0 Yrs\")  # Replace \"2 years\" with your desired value\n",
    "\n",
    "#search_button = WebDriverWait(driver, 10).until(\n",
    "#    EC.element_to_be_clickable((By.XPATH, '//button[contains(@class, \"btn-secondary\")]')))\n",
    "search_button = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')))\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# Click on the \"Search jobs\" button\n",
    "#search_button.click()\n",
    "\n",
    "# Wait for the popup to appear\n",
    "popup = WebDriverWait(driver, 15).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '.modal_modalWrapper__DZCQo')))\n",
    "\n",
    "# Find the \"Close\" button inside the popup\n",
    "close_button = popup.find_element(By.CLASS_NAME, 'btn-close')\n",
    "\n",
    "# Click on the \"Close\" button to close the popup\n",
    "close_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "job_cards = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'jobCard_jobCard__jjUmu')))\n",
    "\n",
    "# Initialize empty lists to store scraped data\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []\n",
    "\n",
    "# Loop through the first 10 job cards\n",
    "for job_card in job_cards[:10]:\n",
    "    job_title_element = job_card.find_element(By.XPATH, './/h2/a')\n",
    "    job_titles.append(job_title_element.text)\n",
    "\n",
    "    job_location_element = job_card.find_element(By.CLASS_NAME, 'jobCard_locationIcon__zrWt2')\n",
    "    job_locations.append(job_location_element.text)\n",
    "\n",
    "    company_name_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_cName__mYnow')\n",
    "    company_names.append(company_name_element.text)\n",
    "\n",
    "    experience_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_lists_item__YxRkV')\n",
    "    experience_required.append(experience_element.text)\n",
    "\n",
    "# Create a dataframe from the scraped data\n",
    "data = {\n",
    "    'Job Title': job_titles,\n",
    "    'Job Location': job_locations,\n",
    "    'Company Name': company_names,\n",
    "    'Experience Required': experience_required\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd36baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>ashutosh sabhashankar chaturvedi hi...</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Urgent Recruiment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apply Now a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apply Now Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needed for Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgently need a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job Title    Job Location  \\\n",
       "0  Project Coordinator (Data Analyst)       Bangalore   \n",
       "1          Data Analyst - Java/Python       Bangalore   \n",
       "2             Hiring For Data Analyst  Bangalore\\n+14   \n",
       "3                 Senior Data Analyst       Bangalore   \n",
       "4                        Data Analyst   Bangalore\\n+9   \n",
       "5      Data Analyst Urgent Recruiment  Bangalore\\n+14   \n",
       "6            Apply Now a Data Analyst       Bangalore   \n",
       "7              Apply Now Data Analyst       Bangalore   \n",
       "8             Needed for Data Analyst       Bangalore   \n",
       "9        Urgently need a Data Analyst       Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                     futures and careers          2 to 4 Yrs  \n",
       "1  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "2                kavya staffing solutions          0 to 4 Yrs  \n",
       "3           ara resources private limited          2 to 5 Yrs  \n",
       "4  ashutosh sabhashankar chaturvedi hi...         7 to 12 Yrs  \n",
       "5                       divya interprises          0 to 4 Yrs  \n",
       "6       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "7       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "8       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "9       deuglo infosystem private limited          1 to 2 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3e4974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>ashutosh sabhashankar chaturvedi hi...</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst Urgent Recruiment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apply Now a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apply Now Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Needed for Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job Title    Job Location  \\\n",
       "0  Project Coordinator (Data Analyst)       Bangalore   \n",
       "1  Project Coordinator (Data Analyst)       Bangalore   \n",
       "2          Data Analyst - Java/Python       Bangalore   \n",
       "3             Hiring For Data Analyst  Bangalore\\n+14   \n",
       "4                 Senior Data Analyst       Bangalore   \n",
       "5                        Data Analyst   Bangalore\\n+9   \n",
       "6      Data Analyst Urgent Recruiment  Bangalore\\n+14   \n",
       "7            Apply Now a Data Analyst       Bangalore   \n",
       "8              Apply Now Data Analyst       Bangalore   \n",
       "9             Needed for Data Analyst       Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                     futures and careers          2 to 4 Yrs  \n",
       "1                     futures and careers          2 to 4 Yrs  \n",
       "2  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "3                kavya staffing solutions          0 to 4 Yrs  \n",
       "4           ara resources private limited          2 to 5 Yrs  \n",
       "5  ashutosh sabhashankar chaturvedi hi...         7 to 12 Yrs  \n",
       "6                       divya interprises          0 to 4 Yrs  \n",
       "7       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "8       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "9       deuglo infosystem private limited          1 to 2 Yrs  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47437f",
   "metadata": {},
   "source": [
    "**Q2**:Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in‚ÄúBangalore‚Äù location. \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter thelocation‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a34dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\2740062030.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "# Specify the path to the manually downloaded ChromeDriver executable\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Step 1: Open the webpage\n",
    "url = \"https://www.shine.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for a few seconds\n",
    "time.sleep(4)\n",
    "\n",
    "# Handle popup if present\n",
    "try:\n",
    "    popup = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".modal_modalWrapper__DZCQo\")))\n",
    "    close_button = popup.find_element(By.CSS_SELECTOR, \".btn-close\")\n",
    "    close_button.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "search_input = driver.find_element(By.CLASS_NAME, \"searchBarInput\")\n",
    "driver.execute_script(\"arguments[0].click();\", search_input)\n",
    "time.sleep(3)\n",
    "search_input = driver.find_element(By.ID, \"id_q\")\n",
    "driver.execute_script(\"arguments[0].value = 'Data Scientist';\", search_input)\n",
    "\n",
    "# Use JavaScript to input \"Bangalore\" into the location field\n",
    "location_element = driver.find_element(By.ID, 'id_loc')\n",
    "driver.execute_script(\"arguments[0].value = 'Bangalore';\", location_element)\n",
    "\n",
    "experience_input = driver.find_element(By.ID, \"id_exp\")\n",
    "\n",
    "# Input the desired experience value (e.g., \"2 years\")\n",
    "experience_input.send_keys(\" 0 Yrs\")  # Replace \"2 years\" with your desired value\n",
    "#clicking on a search button\n",
    "\n",
    "search_button = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')))\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the popup to appear\n",
    "popup = WebDriverWait(driver, 25).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '.modal_modalWrapper__DZCQo')))\n",
    "\n",
    "# Find the \"Close\" button inside the popup\n",
    "close_button = popup.find_element(By.CLASS_NAME, 'btn-close')\n",
    "\n",
    "# Click on the \"Close\" button to close the popup\n",
    "close_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "job_cards = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'jobCard_jobCard__jjUmu')))\n",
    "\n",
    "# Initialize empty lists to store scraped data\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []\n",
    "\n",
    "# Loop through the first 10 job cards\n",
    "for job_card in job_cards[:10]:\n",
    "    job_title_element = job_card.find_element(By.XPATH, './/h2/a')\n",
    "    job_titles.append(job_title_element.text)\n",
    "\n",
    "    job_location_element = job_card.find_element(By.CLASS_NAME, 'jobCard_locationIcon__zrWt2')\n",
    "    job_locations.append(job_location_element.text)\n",
    "\n",
    "    company_name_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_cName__mYnow')\n",
    "    company_names.append(company_name_element.text)\n",
    "\n",
    "    experience_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_lists_item__YxRkV')\n",
    "    experience_required.append(experience_element.text)\n",
    "\n",
    "# Create a dataframe from the scraped data\n",
    "data = {\n",
    "    'Job Title': job_titles,\n",
    "    'Job Location': job_locations,\n",
    "    'Company Name': company_names,\n",
    "    'Experience Required': experience_required\n",
    "}\n",
    "driver.quit()\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6c3e7",
   "metadata": {},
   "source": [
    "**Q3**: In this question you have to scrape data using the filters available on the webpage.\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff77bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\2732516464.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "# Specify the path to the manually downloaded ChromeDriver executable\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Step 1: Open the webpage\n",
    "url = \"https://www.shine.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for a few seconds\n",
    "time.sleep(4)\n",
    "\n",
    "# Handle popup if present\n",
    "try:\n",
    "    popup = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".modal_modalWrapper__DZCQo\")))\n",
    "    close_button = popup.find_element(By.CSS_SELECTOR, \".btn-close\")\n",
    "    close_button.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "search_input = driver.find_element(By.CLASS_NAME, \"searchBarInput\")\n",
    "driver.execute_script(\"arguments[0].click();\", search_input)\n",
    "time.sleep(3)\n",
    "\n",
    "# Locate the \"Advanced Search\" button and click it\n",
    "advanced_search_button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-link\") and contains(text(), \"Advanced Search\")]')\n",
    "advanced_search_button.click()\n",
    "\n",
    "search_input = driver.find_element(By.ID, \"id_q\")\n",
    "driver.execute_script(\"arguments[0].value = 'Data Scientist';\", search_input)\n",
    "\n",
    "\n",
    "location_element = driver.find_element(By.ID, 'id_loc')# Use JavaScript to input \"Bangalore\" into the location field\n",
    "driver.execute_script(\"arguments[0].value = 'Delhi/NCR';\", location_element)\n",
    "\n",
    "\n",
    "experience_input = driver.find_element(By.ID, \"id_exp\")\n",
    "experience_input.send_keys(\" 0 Yrs\") \n",
    "\n",
    "\n",
    "min_salary_input = driver.find_element(By.ID, \"id_minsal\")# Locate the minimum salary input field\n",
    "min_salary_input.send_keys(\"Rs 3.0 - 6.0 Lakh / Yr\")# Enter the desired value\n",
    "\n",
    "\n",
    "\n",
    "area_input = driver.find_element(By.ID, \"id_area\")# Locate the area input field\n",
    "area_input.send_keys(\"Statistics / Analytics / Actuarial Science\")# Enter the desired value\n",
    "\n",
    "\n",
    "\n",
    "industry_input = driver.find_element(By.ID, \"id_ind\")# Locate the industry input field\n",
    "industry_input.send_keys(\"IT Services & Consulting\")# Enter the desired value\n",
    "\n",
    "\n",
    "\n",
    "search_button = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')))\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the popup to appear\n",
    "popup = WebDriverWait(driver, 25).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '.modal_modalWrapper__DZCQo')))\n",
    "\n",
    "# Find the \"Close\" button inside the popup\n",
    "close_button = popup.find_element(By.CLASS_NAME, 'btn-close')\n",
    "\n",
    "# Click on the \"Close\" button to close the popup\n",
    "close_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "job_cards = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'jobCard_jobCard__jjUmu')))\n",
    "\n",
    "# Initialize empty lists to store scraped data\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []\n",
    "\n",
    "# Loop through the first 10 job cards\n",
    "for job_card in job_cards[:10]:\n",
    "    job_title_element = job_card.find_element(By.XPATH, './/h2/a')\n",
    "    job_titles.append(job_title_element.text)\n",
    "\n",
    "    job_location_element = job_card.find_element(By.CLASS_NAME, 'jobCard_locationIcon__zrWt2')\n",
    "    job_locations.append(job_location_element.text)\n",
    "\n",
    "    company_name_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_cName__mYnow')\n",
    "    company_names.append(company_name_element.text)\n",
    "\n",
    "    experience_element = job_card.find_element(By.CLASS_NAME, 'jobCard_jobCard_lists_item__YxRkV')\n",
    "    experience_required.append(experience_element.text)\n",
    "\n",
    "# Create a dataframe from the scraped data\n",
    "data = {\n",
    "    'Job Title': job_titles,\n",
    "    'Job Location': job_locations,\n",
    "    'Company Name': company_names,\n",
    "    'Experience Required': experience_required\n",
    "}\n",
    "driver.quit()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0e17f",
   "metadata": {},
   "source": [
    " **Q4**: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "\n",
    "7. Product\n",
    "\n",
    "8. Description\n",
    "\n",
    "9. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "\n",
    "2. Enter ‚Äúsunglasses‚Äù in the search fieldwhere ‚Äúsearch for products, brands and more‚Äù is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16684991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\3537826593.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from page 1\n",
      "Extracting data from page 2\n",
      "Extracting data from page 3\n",
      "Extracting data from page 4\n",
      "Extracting data from page 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discounted Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>‚Çπ1,999</td>\n",
       "      <td>‚Çπ379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOYAGE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (60)</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (60)</td>\n",
       "      <td>‚Çπ3,000</td>\n",
       "      <td>‚Çπ1,200</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ1,299</td>\n",
       "      <td>‚Çπ204</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>‚Çπ1,599</td>\n",
       "      <td>‚Çπ239</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "      <td>‚Çπ179</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Round Sunglasses (55)</td>\n",
       "      <td>UV Protection Round Sunglasses (55)</td>\n",
       "      <td>‚Çπ4,500</td>\n",
       "      <td>‚Çπ2,375</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Night Vision, Riding Glasses Rectangular Sungl...</td>\n",
       "      <td>Night Vision, Riding Glasses Rectangular Sungl...</td>\n",
       "      <td>‚Çπ1,299</td>\n",
       "      <td>‚Çπ199</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>‚Çπ1,999</td>\n",
       "      <td>‚Çπ764</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (56)</td>\n",
       "      <td>UV Protection Aviator Sunglasses (56)</td>\n",
       "      <td>‚Çπ2,599</td>\n",
       "      <td>‚Çπ323</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>‚Çπ2,500</td>\n",
       "      <td>‚Çπ883</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product Name  \\\n",
       "0     Singco India  Riding Glasses, UV Protection Clubmaster, Wayf...   \n",
       "1           VOYAGE             UV Protection Wayfarer Sunglasses (60)   \n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "3           PIRASO           UV Protection Clubmaster Sunglasses (54)   \n",
       "4        Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "..             ...                                                ...   \n",
       "195    john jacobs                UV Protection Round Sunglasses (55)   \n",
       "196         GANSTA  Night Vision, Riding Glasses Rectangular Sungl...   \n",
       "197      ROYAL SON  Polarized, UV Protection Retro Square Sunglass...   \n",
       "198         PIRASO              UV Protection Aviator Sunglasses (56)   \n",
       "199  VINCENT CHASE  Polarized, UV Protection Rectangular Sunglasse...   \n",
       "\n",
       "                                           Description   Price  \\\n",
       "0    Riding Glasses, UV Protection Clubmaster, Wayf...  ‚Çπ1,999   \n",
       "1               UV Protection Wayfarer Sunglasses (60)  ‚Çπ3,000   \n",
       "2               UV Protection Wayfarer Sunglasses (50)  ‚Çπ1,299   \n",
       "3             UV Protection Clubmaster Sunglasses (54)  ‚Çπ1,599   \n",
       "4    UV Protection Cat-eye, Retro Square, Oval, Rou...    ‚Çπ599   \n",
       "..                                                 ...     ...   \n",
       "195                UV Protection Round Sunglasses (55)  ‚Çπ4,500   \n",
       "196  Night Vision, Riding Glasses Rectangular Sungl...  ‚Çπ1,299   \n",
       "197  Polarized, UV Protection Retro Square Sunglass...  ‚Çπ1,999   \n",
       "198              UV Protection Aviator Sunglasses (56)  ‚Çπ2,599   \n",
       "199  Polarized, UV Protection Rectangular Sunglasse...  ‚Çπ2,500   \n",
       "\n",
       "    Discounted Price Discount  \n",
       "0               ‚Çπ379  81% off  \n",
       "1             ‚Çπ1,200  60% off  \n",
       "2               ‚Çπ204  84% off  \n",
       "3               ‚Çπ239  85% off  \n",
       "4               ‚Çπ179  70% off  \n",
       "..               ...      ...  \n",
       "195           ‚Çπ2,375  47% off  \n",
       "196             ‚Çπ199  84% off  \n",
       "197             ‚Çπ764  61% off  \n",
       "198             ‚Çπ323  87% off  \n",
       "199             ‚Çπ883  64% off  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the manually downloaded ChromeDriver executable\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "\n",
    "# Step 1: Open the Flipkart webpage\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2: Enter \"sunglasses\" in the search field and click the search icon\n",
    "search_box = driver.find_element(By.NAME, 'q')  # Use By.NAME to locate elements by name\n",
    "# Enter the search term\n",
    "search_box.send_keys('sunglasses')\n",
    "# Simulate pressing the Enter key\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Function to extract information from a page\n",
    "def extract_info_from_page(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    sunglasses_divs = soup.find_all('div', class_='_1xHGtK _373qXS')\n",
    "    \n",
    "    sunglasses_list = []\n",
    "    for div in sunglasses_divs:\n",
    "        brand = div.find('div', class_='_2WkVRV').text\n",
    "        product_name = div.find('a', class_='IRpwTa').text\n",
    "        description = div.find('a', class_='IRpwTa')['title']\n",
    "        price_div = div.find('div', class_='_30jeq3')\n",
    "        discounted_price_div = div.find('div', class_='_3I9_wc')\n",
    "        discount_div = div.find('div', class_='_3Ay6Sb')\n",
    "        price = price_div.text if price_div else None\n",
    "        discounted_price = discounted_price_div.text if discounted_price_div else None\n",
    "        discount = discount_div.text if discount_div else None\n",
    "        \n",
    "        sunglasses_list.append({\n",
    "            'Brand': brand,\n",
    "            'Product Name': product_name,\n",
    "            'Description': description,\n",
    "            'Price': discounted_price if discounted_price else price,\n",
    "            'Discounted Price': price if discounted_price else None,\n",
    "            'Discount': discount,\n",
    "        })\n",
    "    \n",
    "    return sunglasses_list\n",
    "\n",
    "# URL of the initial page\n",
    "base_url = \"https://www.flipkart.com\"\n",
    "search_url = \"/search?q=sunglasses&as=on&as-show=on\"\n",
    "url = base_url + search_url\n",
    "\n",
    "# Extract information from multiple pages\n",
    "sunglasses_data = []\n",
    "for page in range(1, 6):  # Extract from up to 5 pages (max 100 sunglasses)\n",
    "    print(f\"Extracting data from page {page}\")\n",
    "    page_data = extract_info_from_page(url)\n",
    "    sunglasses_data.extend(page_data)\n",
    "    \n",
    "    next_page_link = f'/search?q=sunglasses&as=on&as-show=on&otracker=AS_Query_OrganicAutoSuggest_4_10_na_na_ps&otracker1=AS_Query_OrganicAutoSuggest_4_10_na_na_ps&as-pos=4&as-type=RECENT&suggestionId=sunglasses&requestId=9314e63c-9c08-4f38-9fab-34c09aef48d1&as-searchtext=sunglasses&sort=relevance&page={page + 1}'\n",
    "    url = base_url + next_page_link\n",
    "driver.quit()\n",
    "# Create a DataFrame\n",
    "sunglasses_df = pd.DataFrame(sunglasses_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99073b01",
   "metadata": {},
   "source": [
    "**Q5**: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manuall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4287ff75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Photos superREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very goodREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòçREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesomeBest battery backupA performe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at allREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!READ MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good allREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good CameraREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Superüî• and good performance üëå‚ù§Ô∏èREAD MORE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Classy product   \n",
       "1       5             Terrific   \n",
       "2       5    Terrific purchase   \n",
       "3       5       Classy product   \n",
       "4       5            Wonderful   \n",
       "..    ...                  ...   \n",
       "95      5            Just wow!   \n",
       "96      5    Worth every penny   \n",
       "97      5     Perfect product!   \n",
       "98      5  Best in the market!   \n",
       "99      5            Fabulous!   \n",
       "\n",
       "                                          Full Review  \n",
       "0                               Photos superREAD MORE  \n",
       "1                             Very very goodREAD MORE  \n",
       "2                          Value for money üòçREAD MORE  \n",
       "3   Camera is awesomeBest battery backupA performe...  \n",
       "4                     This is amazing at allREAD MORE  \n",
       "..                                                ...  \n",
       "95                         Perfect Product!!READ MORE  \n",
       "96  Feeling awesome after getting the delivery of ...  \n",
       "97                                V Good allREAD MORE  \n",
       "98                               Good CameraREAD MORE  \n",
       "99           Superüî• and good performance üëå‚ù§Ô∏èREAD MORE  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# URL of the reviews page\n",
    "reviews_url = \"https://www.flipkart.com/apple-iphone-11-white-64-gb/product-reviews/itmfc6a7091eb20b?pid=MOBFWQ6BVWVEH3XE&lid=LSTMOBFWQ6BVWVEH3XEMXQMLO&marketplace=FLIPKART\"\n",
    "\n",
    "# Function to scrape reviews data from a given URL\n",
    "def scrape_reviews_data(url, num_reviews=100):\n",
    "    reviews_data = []\n",
    "    while len(reviews_data) < num_reviews:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        review_divs = soup.find_all(\"div\", class_=\"col _2wzgFH K0kLPL\")\n",
    "        \n",
    "        for review_div in review_divs:\n",
    "            rating = review_div.find(\"div\", class_=\"_3LWZlK _1BLPMq\").text.strip()\n",
    "            review_summary = review_div.find(\"p\", class_=\"_2-N8zT\").text.strip()\n",
    "            full_review_div = review_div.find(\"div\", class_=\"t-ZTKy\")\n",
    "            full_review = full_review_div.find(\"div\", class_=\"\").text.strip() if full_review_div else \"\"\n",
    "            \n",
    "            reviews_data.append({\n",
    "                \"Rating\": rating,\n",
    "                \"Review Summary\": review_summary,\n",
    "                \"Full Review\": full_review\n",
    "            })\n",
    "        \n",
    "        next_page = soup.find(\"a\", class_=\"ge-49M\")\n",
    "        if next_page:\n",
    "            url = \"https://www.flipkart.com\" + next_page[\"href\"]\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return reviews_data[:num_reviews]\n",
    "driver.quit()\n",
    "# Scrape reviews data\n",
    "reviews_data = scrape_reviews_data(reviews_url, num_reviews=100)\n",
    "\n",
    "# Create a DataFrame\n",
    "reviews_df = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "reviews_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8dc8c3",
   "metadata": {},
   "source": [
    "**Q6**: Scrape data forfirst 100 sneakers you find whenyou visit flipkart.com and search for ‚Äúsneakers‚Äù inthe\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c45aa2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\584117268.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>‚Çπ369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Hustle V2 Women Sneakers For Men</td>\n",
       "      <td>‚Çπ1,639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rebound LayUp SL Sneakers For Men</td>\n",
       "      <td>‚Çπ2,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Caven Sneakers For Men</td>\n",
       "      <td>‚Çπ2,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>MACTREE</td>\n",
       "      <td>Pro Denim Sneakers For Men</td>\n",
       "      <td>‚Çπ638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>asian</td>\n",
       "      <td>asian Thunder-01 White Color Change Sneakers,C...</td>\n",
       "      <td>‚Çπ940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>R78 Trek Lth Sneakers For Men</td>\n",
       "      <td>‚Çπ1,624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product Description   Price\n",
       "0    Magnolia  Modern Trendy Sneakers boot Sneakers Sneakers ...    ‚Çπ369\n",
       "1      BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ‚Çπ499\n",
       "2      BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ‚Çπ299\n",
       "3        PUMA                   Hustle V2 Women Sneakers For Men  ‚Çπ1,639\n",
       "4        PUMA                  Rebound LayUp SL Sneakers For Men  ‚Çπ2,399\n",
       "..        ...                                                ...     ...\n",
       "115      PUMA                             Caven Sneakers For Men  ‚Çπ2,079\n",
       "116   MACTREE                         Pro Denim Sneakers For Men    ‚Çπ638\n",
       "117     asian  asian Thunder-01 White Color Change Sneakers,C...    ‚Çπ940\n",
       "118    Layasa  Casual Sneakers White Shoes For Girls And Snea...    ‚Çπ599\n",
       "119      PUMA                      R78 Trek Lth Sneakers For Men  ‚Çπ1,624\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Initialize a Chrome WebDriver\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "# Go to the Flipkart sneakers search URL\n",
    "search_url = \"https://www.flipkart.com/\"\n",
    "driver.get(search_url)\n",
    "\n",
    "# Find the search input element and enter \"sneakers\"\n",
    "search_input = driver.find_element(By.CSS_SELECTOR, \"input.Pke_EE\")\n",
    "search_input.send_keys(\"sneakers\")\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Initialize lists to store sneaker data\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "\n",
    "# Function to scrape sneaker data\n",
    "def scrape_sneakers_data(page_url):\n",
    "    driver.get(page_url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    sneaker_divs = soup.find_all(\"div\", class_=\"_2B099V\")\n",
    "\n",
    "    for sneaker_div in sneaker_divs:\n",
    "        brand = sneaker_div.find(\"div\", class_=\"_2WkVRV\").text.strip()\n",
    "        product_description = sneaker_div.find(\"a\", class_=\"IRpwTa\").text.strip()\n",
    "        price = sneaker_div.find(\"div\", class_=\"_30jeq3\").text.strip()\n",
    "\n",
    "        brands.append(brand)\n",
    "        descriptions.append(product_description)\n",
    "        prices.append(price)\n",
    "\n",
    "# Scrape data from multiple pages\n",
    "page_num = 1\n",
    "while len(brands) < 100:\n",
    "    scrape_sneakers_data(driver.current_url)\n",
    "    next_page = driver.find_element(By.CSS_SELECTOR, \"a.ge-49M\")\n",
    "    page_num += 1\n",
    "    next_page.click()\n",
    "\n",
    "    # Wait for the page to load (you might need to adjust the time)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "sneakers_df = pd.DataFrame({\n",
    "    \"Brand\": brands,\n",
    "    \"Product Description\": descriptions,\n",
    "    \"Price\": prices\n",
    "})\n",
    "#quit the driver\n",
    "driver.quit()\n",
    "# Display the DataFrame\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ffedf",
   "metadata": {},
   "source": [
    "**Q7**: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then\n",
    "set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be020579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_15548\\2602080673.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Ratings  \\\n",
      "0  Make the smart choice with Intel-powered lapto...      NA   \n",
      "1                                                 NA      NA   \n",
      "2  Acer Aspire Lite 11th Gen Intel Core i5-1155G7...     3.3   \n",
      "3  Acer Aspire 3 Intel Core i5 12th Generation La...     3.6   \n",
      "4  HP Chromebook 15a Intel Celeron N4500 15.6 inc...     2.1   \n",
      "5  HP Chromebook 15a Intel Celeron N4500 15.6inch...     2.1   \n",
      "6  Acer Extensa 15 AMD Ryzen‚Ñ¢ 3 7320U Quad-Core P...     4.0   \n",
      "7                                                 NA     4.2   \n",
      "8                                                 NA     4.2   \n",
      "9                                                 NA     4.2   \n",
      "\n",
      "                                              Price  \n",
      "0  Make the smart choice with Intel-powered laptops  \n",
      "1                                                NA  \n",
      "2                                           ‚Çπ41,990  \n",
      "3                                           ‚Çπ50,999  \n",
      "4                                           ‚Çπ17,990  \n",
      "5                                           ‚Çπ17,990  \n",
      "6                                           ‚Çπ26,990  \n",
      "7                                           ‚Çπ64,990  \n",
      "8                                           ‚Çπ64,990  \n",
      "9                                           ‚Çπ61,990  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the Selenium WebDriver (ensure you have the appropriate webdriver executable)\n",
    "# Initialize a Chrome WebDriver\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "# Open Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Find the search input field, enter \"Laptop\", and press Enter\n",
    "search_input = driver.find_element(By.XPATH, \"//input[@aria-label='Search Amazon.in']\")\n",
    "search_input.send_keys(\"Laptop\")\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the page to load and find the \"Intel Core i7\" filter\n",
    "time.sleep(2)  # Adjust the wait time if needed\n",
    "# Apply the \"Intel Core i7\" filter\n",
    "i7_filter = driver.find_element(By.XPATH, '//span[text()=\"Intel Core i7\"]')\n",
    "i7_filter.click()\n",
    "\n",
    "# Wait for the page to load after applying the filter\n",
    "time.sleep(2)  # Adjust the wait time if needed\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Close the WebDriver\n",
    "#driver.quit()\n",
    "\n",
    "# Parse the page source with BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all laptop containers\n",
    "laptop_containers = soup.find_all('div', class_='s-result-item')\n",
    "\n",
    "# Initialize lists to store data\n",
    "titles = []\n",
    "ratings = []\n",
    "prices = []\n",
    "\n",
    "# Loop through the laptop containers and extract required info\n",
    "for laptop in laptop_containers[:10]:  # Scraping first 10 laptops\n",
    "    title_element = laptop.find('span', class_='a-size-medium')\n",
    "    rating_element = laptop.find('span', class_='a-icon-alt')\n",
    "    price_element = laptop.find('span', class_='a-offscreen')\n",
    "\n",
    "    title = title_element.get_text().strip() if title_element else \"NA\"\n",
    "    rating = rating_element.get_text().split()[0] if rating_element else \"NA\"\n",
    "    price = price_element.get_text() if price_element else \"NA\"\n",
    "\n",
    "    titles.append(title)\n",
    "    ratings.append(rating)\n",
    "    prices.append(price)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Title': titles, 'Ratings': ratings, 'Price': prices}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019f72e",
   "metadata": {},
   "source": [
    " **Q8**: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74c8033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type Of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Be more concerned with your character than you...</td>\n",
       "      <td>John Wooden</td>\n",
       "      <td>Inspirational, Success, Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weak people revenge. Strong people forgive. In...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Strong, Revenge, Intelligent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A mind is like a parachute. It doesn't work if...</td>\n",
       "      <td>Frank Zappa</td>\n",
       "      <td>Inspirational, Teacher, Religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Never be afraid to raise your voice for honest...</td>\n",
       "      <td>William Faulkner</td>\n",
       "      <td>Truth, Honesty, Lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There are three kinds of men. The one that lea...</td>\n",
       "      <td>Will Rogers</td>\n",
       "      <td>Funny, Reading, Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote              Author  \\\n",
       "0  The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1  One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2  Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3  Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4  You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "5  Be more concerned with your character than you...         John Wooden   \n",
       "6  Weak people revenge. Strong people forgive. In...     Albert Einstein   \n",
       "7  A mind is like a parachute. It doesn't work if...         Frank Zappa   \n",
       "8  Never be afraid to raise your voice for honest...    William Faulkner   \n",
       "9  There are three kinds of men. The one that lea...         Will Rogers   \n",
       "\n",
       "                             Type Of Quotes  \n",
       "0  Essence, Deep Thought, Transcendentalism  \n",
       "1                 Inspiration, Past, Trying  \n",
       "2                       Country, Peace, War  \n",
       "3        Inspirational, Motivational, Death  \n",
       "4              4th Of July, Food, Patriotic  \n",
       "5        Inspirational, Success, Basketball  \n",
       "6              Strong, Revenge, Intelligent  \n",
       "7         Inspirational, Teacher, Religious  \n",
       "8                     Truth, Honesty, Lying  \n",
       "9                  Funny, Reading, Learning  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL for the Top Quotes page\n",
    "url = 'https://www.azquotes.com/top_quotes.html'\n",
    "\n",
    "# Send a GET request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all quote elements\n",
    "quote_elements = soup.find_all('div', {'class': 'wrap-block'})\n",
    "\n",
    "# List to store scraped data\n",
    "quotes_data = []\n",
    "\n",
    "# Loop through quote elements and extract data\n",
    "for element in quote_elements:\n",
    "    quote = element.find('a', {'class': 'title'}).text.strip()\n",
    "    author = element.find('div', {'class': 'author'}).find('a').text\n",
    "    types = [tag.text for tag in element.find_all('a', {'href': lambda href: href and '/quotes/topics/' in href})]\n",
    "\n",
    "    quotes_data.append({\n",
    "        'Quote': quote,\n",
    "        'Author': author,\n",
    "        'Type Of Quotes': ', '.join(types)\n",
    "    })\n",
    "driver.quit()\n",
    "# Create a DataFrame from the collected data\n",
    "quotes_df = pd.DataFrame(quotes_data)\n",
    "\n",
    "# Print the first 10 quotes for verification\n",
    "#print(quotes_df.head(10))\n",
    "quotes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b07a69",
   "metadata": {},
   "source": [
    "**Q9**: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11254b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\3862381092.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904‚Äì1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896‚Äì1995)</td>\n",
       "      <td>24 March 1977 to¬† 28 July 1979</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902‚Äì1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944‚Äì1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931‚Äì2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927‚Äì2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>He belongs to ¬†Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921‚Äì2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>He belongs to¬† Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919‚Äì2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name     Born-Dead  \\\n",
       "0           Jawahar Lal Nehru   (1889‚Äì1964)   \n",
       "1   Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2         Lal Bahadur Shastri   (1904‚Äì1966)   \n",
       "3               Indira Gandhi   (1917‚Äì1984)   \n",
       "4               Morarji Desai   (1896‚Äì1995)   \n",
       "5                Charan Singh   (1902‚Äì1987)   \n",
       "6               Indira Gandhi   (1917‚Äì1984)   \n",
       "7                Rajiv Gandhi   (1944‚Äì1991)   \n",
       "8                 V. P. Singh   (1931‚Äì2008)   \n",
       "9             Chandra Shekhar   (1927‚Äì2007)   \n",
       "10        P. V. Narasimha Rao   (1921‚Äì2004)   \n",
       "11       Atal Bihari Vajpayee  (1924- 2018)   \n",
       "12           H. D. Deve Gowda   (born 1933)   \n",
       "13         Inder Kumar Gujral   (1919‚Äì2012)   \n",
       "14       Atal Bihari Vajpayee   (1924-2018)   \n",
       "15             Manmohan Singh   (born 1932)   \n",
       "16              Narendra Modi   (born 1950)   \n",
       "17              Narendra Modi   (born 1950)   \n",
       "\n",
       "                         Term of office  \\\n",
       "0         15 August 1947 to 27 May 1964   \n",
       "1           27 May 1964 to 9 June 1964,   \n",
       "2        9 June 1964 to 11 January 1966   \n",
       "3      24 January 1966 to 24 March 1977   \n",
       "4      24 March 1977 to¬† 28 July 1979¬†    \n",
       "5       28 July 1979 to 14 January 1980   \n",
       "6    14 January 1980 to 31 October 1984   \n",
       "7    31 October 1984 to 2 December 1989   \n",
       "8   2 December 1989 to 10 November 1990   \n",
       "9      10 November 1990 to 21 June 1991   \n",
       "10          21 June 1991 to 16 May 1996   \n",
       "11           16 May 1996 to 1 June 1996   \n",
       "12         1 June 1996 to 21 April 1997   \n",
       "13     21 April 1997 to 19 March 1998¬†    \n",
       "14        19 March 1998 to 22 May 2004¬†   \n",
       "15        22 May 2004 to 26 May 2014¬†¬†¬†   \n",
       "16                   26 May 2014 - 2019   \n",
       "17               30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                First female Prime Minister of India  \n",
       "4   Oldest to become PM (81 years old) and first t...  \n",
       "5             Only PM who did not face the Parliament  \n",
       "6   The first lady who served as PM for the second...  \n",
       "7                Youngest to become PM (40 years old)  \n",
       "8   First PM to step down after a vote of no confi...  \n",
       "9               He belongs to ¬†Samajwadi Janata Party  \n",
       "10                          First PM from South India  \n",
       "11                             PM for shortest tenure  \n",
       "12                          He belongs to¬† Janata Dal  \n",
       "13                                             ------  \n",
       "14  ¬†The first non-congress PM who completed a ful...  \n",
       "15                                     ¬†First Sikh PM  \n",
       "16  4th Prime Minister of India who served two con...  \n",
       "17  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys  # Import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "# Open the jagranjosh URL\n",
    "\n",
    "# Open the jagranjosh URL\n",
    "url = 'https://www.jagranjosh.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Click on the \"GK\" option\n",
    "gk_option = driver.find_element(By.LINK_TEXT, 'GK')\n",
    "gk_option.click()\n",
    "\n",
    "# Scroll down to reveal the \"List of all Prime Ministers of India\" link\n",
    "driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "time.sleep(1)\n",
    "\n",
    "# Try clicking on the \"List of all Prime Ministers of India\" link\n",
    "try:\n",
    "    prime_ministers_link = driver.find_element(By.LINK_TEXT, 'List of all Prime Ministers of India')\n",
    "    prime_ministers_link.click()\n",
    "except:\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    prime_ministers_link = driver.find_element(By.LINK_TEXT, 'List of all Prime Ministers of India')\n",
    "    prime_ministers_link.click()\n",
    "\n",
    "# Get the HTML content of the page\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all table rows containing the data\n",
    "table_rows = soup.find_all('tr')\n",
    "\n",
    "# List to store scraped data\n",
    "prime_ministers_data = []\n",
    "\n",
    "for row in table_rows:\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        name_element = columns[1].find('p')\n",
    "        born_dead_element = columns[2].find('p')\n",
    "        term_of_office_elements = columns[3].find_all('span')\n",
    "        remarks_element = columns[4].find('p')\n",
    "        \n",
    "        if name_element and born_dead_element and term_of_office_elements and remarks_element:\n",
    "            name = name_element.text\n",
    "            born_dead = born_dead_element.text\n",
    "            term_of_office = term_of_office_elements[0].text\n",
    "            remarks = remarks_element.text\n",
    "\n",
    "            prime_ministers_data.append({\n",
    "                'Name': name,\n",
    "                'Born-Dead': born_dead,\n",
    "                'Term of office': term_of_office,\n",
    "                'Remarks': remarks\n",
    "            })\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "prime_ministers_df = pd.DataFrame(prime_ministers_data)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "prime_ministers_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e19e6",
   "metadata": {},
   "source": [
    "**Q10**: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6184d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganvir\\AppData\\Local\\Temp\\ipykernel_1920\\3908670435.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Car Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>$1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emira</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eletre</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>$1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Project One</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>$2.1 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Car Name     Car Price\n",
       "0          Koenigsegg Gemera  $1.5 Million\n",
       "1         Hennessey Venom F5  $1.7 Million\n",
       "2                      Emira  $1.7 Million\n",
       "3                     Eletre  $1.7 Million\n",
       "4        Aston Martin Vulcan  $1.7 Million\n",
       "5          McLaren Speedtail  $1.7 Million\n",
       "6               Rimac Nevera  $1.7 Million\n",
       "7       Pininfarina Battista  $1.8 Million\n",
       "8       Lamborghini Countach  $1.9 Million\n",
       "9   Mercedes-AMG Project One  $1.9 Million\n",
       "10               Project One  $2.0 Million\n",
       "11          Koenigsegg Jesko  $2.0 Million\n",
       "12     Aston Martin Valkyrie  $2.0 Million\n",
       "13              Bugatti Divo  $2.1 Million"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "chrome_driver_path = r'C:\\Users\\Ganvir\\Downloads\\Webscraping Assignment-2\\chromedriver.exe'  # Update this with the actual path\n",
    "\n",
    "# Initialize the WebDriver using the specified path\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Open the motor1 URL\n",
    "url = 'https://www.motor1.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Type \"50 Most Expensive Cars In The World\" in the search box\n",
    "search_box = driver.find_element(By.ID, 'search_input')\n",
    "search_box.send_keys(\"50 Most Expensive Cars In The World\")\n",
    "search_box.submit()\n",
    "\n",
    "# Click on the \"50 Most Expensive Cars In The World\" link\n",
    "expensive_cars_link = driver.find_element(By.LINK_TEXT, '50 Most Expensive Cars In The World')\n",
    "expensive_cars_link.click()\n",
    "\n",
    "# Get the HTML content of the page\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all car name and price elements\n",
    "car_name_elements = soup.find_all('a', {'data-type-id': '1'})\n",
    "car_price_elements = soup.find_all('strong', string=re.compile(r'^Price:'))\n",
    "\n",
    "# List to store scraped data\n",
    "cars_data = []\n",
    "\n",
    "# Loop through car name and price elements and extract data\n",
    "for car_name_element, car_price_element in zip(car_name_elements, car_price_elements):\n",
    "    car_name = car_name_element.text\n",
    "    car_price = car_price_element.text.replace('Price:', '').strip()\n",
    "    \n",
    "    cars_data.append({\n",
    "        'Car Name': car_name,\n",
    "        'Car Price': car_price\n",
    "    })\n",
    "driver.quit()\n",
    "# Create a DataFrame from the collected data\n",
    "cars_df = pd.DataFrame(cars_data)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "cars_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b62db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
