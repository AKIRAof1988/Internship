{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbf1e5b",
   "metadata": {},
   "source": [
    "**1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:**\n",
    "\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date \n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36b1484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.29</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.25</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.78</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.38</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.07</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.01</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.53</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.47</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.02</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.96</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.88</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.43</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.04</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.93</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.86</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.86</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.76</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.70</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.67</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.65</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.58</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.54</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.53</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.51</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.50</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.45</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.45</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                               Name  \\\n",
       "0    1.                   Baby Shark Dance   \n",
       "1    2.                          Despacito   \n",
       "2    3.               Johny Johny Yes Papa   \n",
       "3    4.                               [17]   \n",
       "4    5.                       Shape of You   \n",
       "5    6.                      See You Again   \n",
       "6    7.                  Wheels on the Bus   \n",
       "7    8.                               [27]   \n",
       "8    9.                        Uptown Funk   \n",
       "9   10.                               [29]   \n",
       "10  11.                      Gangnam Style   \n",
       "11  12.                 Masha and the Bear   \n",
       "12  13.                     Dame Tu Cosita   \n",
       "13  14.                             Axel F   \n",
       "14  15.                              Sugar   \n",
       "15  16.                     Counting Stars   \n",
       "16  17.                               Roar   \n",
       "17  18.                Baa Baa Black Sheep   \n",
       "18  19.   Waka Waka (This Time for Africa)   \n",
       "19  20.                              Sorry   \n",
       "20  21.                     Lakdi Ki Kathi   \n",
       "21  22.                  Thinking Out Loud   \n",
       "22  23.                         Dark Horse   \n",
       "23  24.  Humpty the train on a fruits ride   \n",
       "24  25.                            Perfect   \n",
       "25  26.                              Faded   \n",
       "26  27.                         Let Her Go   \n",
       "27  28.                     Girls Like You   \n",
       "28  29.                            Lean On   \n",
       "29  30.                           Bailando   \n",
       "\n",
       "                                               Artist Views (billions)  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories            13.29   \n",
       "1                                          Luis Fonsi             8.25   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs             6.78   \n",
       "3                          Cocomelon - Nursery Rhymes             6.38   \n",
       "4                                          Ed Sheeran             6.07   \n",
       "5                                         Wiz Khalifa             6.01   \n",
       "6                          Cocomelon - Nursery Rhymes             5.53   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs             5.47   \n",
       "8                                         Mark Ronson             5.02   \n",
       "9                                         Miroshka TV             4.96   \n",
       "10                                        officialpsy             4.88   \n",
       "11                                         Get Movies             4.56   \n",
       "12                                      Ultra Records             4.43   \n",
       "13                                         Crazy Frog             4.04   \n",
       "14                                           Maroon 5             3.93   \n",
       "15                                        OneRepublic             3.86   \n",
       "16                                         Katy Perry             3.86   \n",
       "17                         Cocomelon - Nursery Rhymes             3.76   \n",
       "18                                            Shakira             3.71   \n",
       "19                                      Justin Bieber             3.70   \n",
       "20                                       Jingle Toons             3.67   \n",
       "21                                         Ed Sheeran             3.65   \n",
       "22                                         Katy Perry             3.58   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs             3.54   \n",
       "24                                         Ed Sheeran             3.53   \n",
       "25                                        Alan Walker             3.51   \n",
       "26                                          Passenger             3.50   \n",
       "27                                           Maroon 5             3.47   \n",
       "28                               Major Lazer Official             3.45   \n",
       "29                                   Enrique Iglesias             3.45   \n",
       "\n",
       "     Publication date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25   December 3, 2015  \n",
       "26      July 25, 2012  \n",
       "27       May 31, 2018  \n",
       "28     March 22, 2015  \n",
       "29     April 11, 2014  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Finding the table containing the information\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "# Extracting the rows\n",
    "rows = table.find_all(\"tr\")[1:]  # Skip the header row\n",
    "\n",
    "# Initialize lists to store the data\n",
    "rank_list = []\n",
    "name_list = []\n",
    "artist_list = []\n",
    "date_list = []\n",
    "views_list = []\n",
    "\n",
    "# Loop through the rows and extract the information\n",
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:  # Ensure there are enough columns\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].find(\"a\").text\n",
    "        artist = columns[2].text\n",
    "        views = columns[3].text\n",
    "        date = columns[4].text.strip()\n",
    "\n",
    "        rank_list.append(rank)\n",
    "        name_list.append(name)\n",
    "        artist_list.append(artist)\n",
    "        date_list.append(date)\n",
    "        views_list.append(views)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Rank\": rank_list,\n",
    "    \"Name\": name_list,\n",
    "    \"Artist\": artist_list,\n",
    "    \"Views (billions)\": views_list,\n",
    "    \"Publication date\": date_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4191ba0",
   "metadata": {},
   "source": [
    "**2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:**\n",
    "\n",
    "A) Match title (I.e. 1sOt DI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e319fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f7/7l8ws9yx7ybdzmwks1n4tty00000gn/T/ipykernel_10777/423312392.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tournament Name: ASIA CUP 2023\n",
      "Match Date: 15 SEP 2023\n",
      "Match Time: 3:00 PM IST\n",
      "Team 1: India\n",
      "Team 2: Bangladesh\n",
      "Ground Name: R Premadasa International Stadium,\n",
      "City: Colombo\n",
      "\n",
      "\n",
      "Tournament Name: 19TH ASIAN GAMES 2023\n",
      "Match Date: 21 SEP 2023\n",
      "Match Time: 6:30 AM IST\n",
      "Team 1: India Women\n",
      "Team 2: TBD\n",
      "Ground Name: Pingfeng Cricket Field,\n",
      "City: Hangzhou\n",
      "\n",
      "\n",
      "Tournament Name: AUSTRALIA TOUR OF INDIA 2023-24\n",
      "Match Date: 22 SEP 2023\n",
      "Match Time: 1:30 PM IST\n",
      "Team 1: India\n",
      "Team 2: Australia\n",
      "Ground Name: Punjab Cricket Association IS Bindra Stadium,\n",
      "City: Mohali\n",
      "\n",
      "\n",
      "Tournament Name: AUSTRALIA TOUR OF INDIA 2023-24\n",
      "Match Date: 24 SEP 2023\n",
      "Match Time: 1:30 PM IST\n",
      "Team 1: India\n",
      "Team 2: Australia\n",
      "Ground Name: Holkar Cricket Stadium,\n",
      "City: Indore\n",
      "\n",
      "\n",
      "Tournament Name: AUSTRALIA TOUR OF INDIA 2023-24\n",
      "Match Date: 27 SEP 2023\n",
      "Match Time: 1:30 PM IST\n",
      "Team 1: India\n",
      "Team 2: Australia\n",
      "Ground Name: Saurashtra Cricket Association Stadium,\n",
      "City: Rajkot\n",
      "\n",
      "\n",
      "Tournament Name: ICC MENS WORLD CUP 2023 WARM-UP MATCHES\n",
      "Match Date: 30 SEP 2023\n",
      "Match Time: 2:00 PM IST\n",
      "Team 1: India\n",
      "Team 2: England\n",
      "Ground Name: Barsapara Cricket Stadium,\n",
      "City: Guwahati\n",
      "\n",
      "\n",
      "Tournament Name: 19TH ASIAN GAMES 2023\n",
      "Match Date: 3 OCT 2023\n",
      "Match Time: 6:30 AM IST\n",
      "Team 1: India\n",
      "Team 2: TBD\n",
      "Ground Name: Pingfeng Cricket Field,\n",
      "City: Hangzhou\n",
      "\n",
      "\n",
      "Tournament Name: ICC MENS WORLD CUP 2023 WARM-UP MATCHES\n",
      "Match Date: 3 OCT 2023\n",
      "Match Time: 2:00 PM IST\n",
      "Team 1: India\n",
      "Team 2: Netherlands\n",
      "Ground Name: Greenfield International Stadium,\n",
      "City: Thiruvananthapuram\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize the webdriver (make sure you have the appropriate driver installed)\n",
    "webdriver_path = \"/Users/siddhant/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "\n",
    "\n",
    "# Step 1: Go to the URL\n",
    "#driver.get(\"https://www.bcci.tv/\")\n",
    "# Step 1: Go to the URL\n",
    "driver.get(\"https://www.bcci.tv/international/fixtures\")\n",
    "\n",
    "\n",
    "# Step 5: Extract the information\n",
    "upcoming_matches = driver.find_elements(By.CLASS_NAME, \"col-lg-4\")\n",
    "\n",
    "# Initialize lists to store the data\n",
    "tournament_name_list = []\n",
    "match_date_list = []\n",
    "match_time_list = []\n",
    "team1_name_list = []\n",
    "team2_name_list = []\n",
    "ground_name_list = []\n",
    "city_list = []\n",
    "\n",
    "# Loop through the match cards and extract the information\n",
    "for match_card in upcoming_matches:\n",
    "    tournament_name = match_card.find_element(By.CLASS_NAME, \"match-tournament-name\").text.strip()\n",
    "    match_date = match_card.find_element(By.CLASS_NAME, \"match-dates\").text.strip()\n",
    "    match_time = match_card.find_element(By.CLASS_NAME, \"match-time\").text.strip()\n",
    "    team_names = match_card.find_elements(By.CLASS_NAME, \"tm-name\")\n",
    "    team1_name = team_names[0].text.strip()\n",
    "    team2_name = team_names[1].text.strip()\n",
    "    location_info = match_card.find_elements(By.CLASS_NAME, \"ng-binding\")\n",
    "    ground_name = location_info[-2].text.strip()\n",
    "    city = location_info[-1].text.strip()\n",
    "\n",
    "    tournament_name_list.append(tournament_name)\n",
    "    match_date_list.append(match_date)\n",
    "    match_time_list.append(match_time)\n",
    "    team1_name_list.append(team1_name)\n",
    "    team2_name_list.append(team2_name)\n",
    "    ground_name_list.append(ground_name)\n",
    "    city_list.append(city)\n",
    "\n",
    "# Print the extracted information\n",
    "for i in range(len(tournament_name_list)):\n",
    "    print(f\"Tournament Name: {tournament_name_list[i]}\")\n",
    "    print(f\"Match Date: {match_date_list[i]}\")\n",
    "    print(f\"Match Time: {match_time_list[i]}\")\n",
    "    print(f\"Team 1: {team1_name_list[i]}\")\n",
    "    print(f\"Team 2: {team2_name_list[i]}\")\n",
    "    print(f\"Ground Name: {ground_name_list[i]}\")\n",
    "    print(f\"City: {city_list[i]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c40c5b",
   "metadata": {},
   "source": [
    "**3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:**\n",
    "A) Rank\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)- at current prices\n",
    "\n",
    "D) GSDP(19-20)- at current prices\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a332abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f7/7l8ws9yx7ybdzmwks1n4tty00000gn/T/ipykernel_1218/3211650236.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(18-19) GSDP(19-20) Share(18-19)  \\\n",
      "0     1                Maharashtra           -   2,632,792       13.94%   \n",
      "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
      "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
      "3     4                    Gujarat           -   1,502,899        7.96%   \n",
      "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
      "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
      "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
      "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
      "8     9                  Telangana     969,604     861,031        4.56%   \n",
      "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
      "10   11                     Kerala           -     781,653        4.14%   \n",
      "11   12                      Delhi     856,112     774,870        4.10%   \n",
      "12   13                    Haryana     831,610     734,163        3.89%   \n",
      "13   14                      Bihar     611,804     530,363        2.81%   \n",
      "14   15                     Punjab     574,760     526,376        2.79%   \n",
      "15   16                     Odisha     521,275     487,805        2.58%   \n",
      "16   17                      Assam           -     315,881        1.67%   \n",
      "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
      "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
      "19   20                Uttarakhand           -     245,895        1.30%   \n",
      "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
      "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
      "22   23                        Goa      80,449      73,170        0.39%   \n",
      "23   24                    Tripura      55,984      49,845        0.26%   \n",
      "24   25                 Chandigarh           -      42,114        0.22%   \n",
      "25   26                 Puducherry      38,253      34,433        0.18%   \n",
      "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
      "27   28                     Sikkim      32,496      28,723        0.15%   \n",
      "28   29                    Manipur      31,790      27,870        0.15%   \n",
      "29   30                   Nagaland           -      27,283        0.14%   \n",
      "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
      "31   32                    Mizoram      26,503      22,287        0.12%   \n",
      "32   33  Andaman & Nicobar Islands           -           -            -   \n",
      "33                           India  20,351,013  18,886,957                \n",
      "\n",
      "   GDP($ billion)  \n",
      "0         399.921  \n",
      "1         247.629  \n",
      "2         240.726  \n",
      "3         228.290  \n",
      "4         226.806  \n",
      "5         165.556  \n",
      "6         143.179  \n",
      "7         131.083  \n",
      "8         130.791  \n",
      "9         122.977  \n",
      "10        118.733  \n",
      "11        117.703  \n",
      "12        111.519  \n",
      "13         80.562  \n",
      "14         79.957  \n",
      "15         74.098  \n",
      "16         47.982  \n",
      "17         46.187  \n",
      "18         45.145  \n",
      "19         37.351  \n",
      "20         23.690  \n",
      "21         23.369  \n",
      "22         11.115  \n",
      "23          7.571  \n",
      "24          6.397  \n",
      "25          5.230  \n",
      "26          5.086  \n",
      "27          4.363  \n",
      "28          4.233  \n",
      "29          4.144  \n",
      "30          3.737  \n",
      "31          3.385  \n",
      "32              -  \n",
      "33          2,869  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "# Define the URL\n",
    "url = \"https://www.statisticstimes.com/economy/india/indian-states-gdp.php\"\n",
    "\n",
    "# Specify the path to the webdriver\n",
    "webdriver_path = \"/Users/siddhant/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "\n",
    "# Open the URL\n",
    "driver.get(url)\n",
    "\n",
    "# Find the table containing the information\n",
    "table = driver.find_element(By.ID, \"table_id\")\n",
    "\n",
    "# Find all the rows in the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through the rows and extract the information\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    \n",
    "    # Check if there are enough columns in the row\n",
    "    if len(columns) >= 6:\n",
    "        rank = columns[0].text\n",
    "        state = columns[1].text\n",
    "        gdp_18_19 = columns[2].text\n",
    "        gdp_19_20 = columns[3].text\n",
    "        share_18_19 = columns[4].text\n",
    "        gdp_billion = columns[5].text\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append((rank, state, gdp_18_19, gdp_19_20, share_18_19, gdp_billion))\n",
    "        df = pd.DataFrame(data, columns=['Rank', 'State', 'GSDP(18-19)', 'GSDP(19-20)', 'Share(18-19)', 'GDP($ billion)'])\n",
    "\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73d472",
   "metadata": {},
   "source": [
    "**4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/**\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6261dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f7/7l8ws9yx7ybdzmwks1n4tty00000gn/T/ipykernel_1218/3874892882.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title  \\\n",
      "0                     hyperdxio / hyperdx   \n",
      "1      williamyang1991 / Rerender_A_Video   \n",
      "2                     NExT-GPT / NExT-GPT   \n",
      "3                       makeplane / plane   \n",
      "4                         grafana / beyla   \n",
      "5     CorentinJ / Real-Time-Voice-Cloning   \n",
      "6                     mastodon / mastodon   \n",
      "7   AntonioErdeljac / next13-lms-platform   \n",
      "8                         TabbyML / tabby   \n",
      "9                        basecamp / kamal   \n",
      "10                    godotengine / godot   \n",
      "11                       vercel / next.js   \n",
      "12               ripienaar / free-for-dev   \n",
      "13                    aiwaves-cn / agents   \n",
      "14             duckduckgo / tracker-radar   \n",
      "15                  Alamofire / Alamofire   \n",
      "16                         coqui-ai / TTS   \n",
      "17                    sczhou / ProPainter   \n",
      "18        aras-p / UnityGaussianSplatting   \n",
      "19                 Snailclimb / JavaGuide   \n",
      "20        WooooDyy / LLM-Agent-Paper-List   \n",
      "21        MunGell / awesome-for-beginners   \n",
      "22                           fmtlib / fmt   \n",
      "23                      meshery / meshery   \n",
      "24               langchain-ai / langchain   \n",
      "\n",
      "                                          Description Contributors Count  \\\n",
      "0   Resolve production issues, fast. An open sourc...           Built by   \n",
      "1   [SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...           Built by   \n",
      "2   Code and models for NExT-GPT: Any-to-Any Multi...           Built by   \n",
      "3   🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...           Built by   \n",
      "4   eBPF-based autoinstrumentation of HTTP and HTT...           Built by   \n",
      "5   Clone a voice in 5 seconds to generate arbitra...           Built by   \n",
      "6   Your self-hosted, globally interconnected micr...           Built by   \n",
      "7                             No description provided           Built by   \n",
      "8                     Self-hosted AI coding assistant           Built by   \n",
      "9                           Deploy web apps anywhere.           Built by   \n",
      "10  Godot Engine – Multi-platform 2D and 3D game e...           Built by   \n",
      "11                                The React Framework           Built by   \n",
      "12  A list of SaaS, PaaS and IaaS offerings that h...           Built by   \n",
      "13  An Open-source Framework for Autonomous Langua...           Built by   \n",
      "14  Data set of top third party web domains with r...           Built by   \n",
      "15                   Elegant HTTP Networking in Swift           Built by   \n",
      "16  🐸💬 - a deep learning toolkit for Text-to-Speec...           Built by   \n",
      "17  [ICCV 2023] ProPainter: Improving Propagation ...           Built by   \n",
      "18      Toy Gaussian Splatting visualization in Unity           Built by   \n",
      "19  「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...           Built by   \n",
      "20  The paper list of the 86-page paper \"The Rise ...           Built by   \n",
      "21     A list of awesome beginners-friendly projects.           Built by   \n",
      "22                        A modern formatting library           Built by   \n",
      "23                  Meshery, the cloud native manager           Built by   \n",
      "24  ⚡ Building applications with LLMs through comp...           Built by   \n",
      "\n",
      "                 Language  \n",
      "0              TypeScript  \n",
      "1        Jupyter Notebook  \n",
      "2                  Python  \n",
      "3              TypeScript  \n",
      "4                       C  \n",
      "5                  Python  \n",
      "6                    Ruby  \n",
      "7              TypeScript  \n",
      "8              TypeScript  \n",
      "9                    Ruby  \n",
      "10                    C++  \n",
      "11             JavaScript  \n",
      "12                   HTML  \n",
      "13                 Python  \n",
      "14             JavaScript  \n",
      "15                  Swift  \n",
      "16                 Python  \n",
      "17                 Python  \n",
      "18                     C#  \n",
      "19                   Java  \n",
      "20  No language specified  \n",
      "21  No language specified  \n",
      "22                    C++  \n",
      "23                     Go  \n",
      "24                 Python  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Initialize the web driver\n",
    "webdriver_path = \"/Users/siddhant/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "\n",
    "# Step 2: Open the URL\n",
    "url = \"https://github.com/trending\"\n",
    "driver.get(url)\n",
    "\n",
    "# Step 3: Wait for repositories to load\n",
    "wait = WebDriverWait(driver, 10) \n",
    "repositories = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"Box-row\")))\n",
    "\n",
    "# Initialize lists to store data\n",
    "titles = []\n",
    "descriptions = []\n",
    "contributors_counts = []\n",
    "languages = []\n",
    "\n",
    "# Step 4: Loop through the repositories and extract information\n",
    "for repo in repositories:\n",
    "    title_element = repo.find_element(By.XPATH, \".//h2/a\")\n",
    "    contributors_count_element = repo.find_element(By.XPATH, \".//a[contains(@href,'/stargazers')]/following-sibling::span\")\n",
    "    \n",
    "    try:\n",
    "        description_element = repo.find_element(By.TAG_NAME, \"p\")\n",
    "        descriptions.append(description_element.text)\n",
    "    except:\n",
    "        descriptions.append(\"No description provided\")\n",
    "\n",
    "    try:\n",
    "        language_element = repo.find_element(By.CSS_SELECTOR, \"span[itemprop='programmingLanguage']\")\n",
    "        languages.append(language_element.text)\n",
    "    except:\n",
    "        languages.append(\"No language specified\")\n",
    "\n",
    "    titles.append(title_element.text)\n",
    "    contributors_counts.append(contributors_count_element.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = {'Title': titles, 'Description': descriptions, 'Contributors Count': contributors_counts, 'Language': languages}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print or use the DataFrame as needed\n",
    "print(df)\n",
    "\n",
    "# Step 6: Close the web driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fa494ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperdxio / hyperdx</td>\n",
       "      <td>Resolve production issues, fast. An open sourc...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>williamyang1991 / Rerender_A_Video</td>\n",
       "      <td>[SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NExT-GPT / NExT-GPT</td>\n",
       "      <td>Code and models for NExT-GPT: Any-to-Any Multi...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>makeplane / plane</td>\n",
       "      <td>🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grafana / beyla</td>\n",
       "      <td>eBPF-based autoinstrumentation of HTTP and HTT...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CorentinJ / Real-Time-Voice-Cloning</td>\n",
       "      <td>Clone a voice in 5 seconds to generate arbitra...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mastodon / mastodon</td>\n",
       "      <td>Your self-hosted, globally interconnected micr...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AntonioErdeljac / next13-lms-platform</td>\n",
       "      <td>No description provided</td>\n",
       "      <td>Built by</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabbyML / tabby</td>\n",
       "      <td>Self-hosted AI coding assistant</td>\n",
       "      <td>Built by</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basecamp / kamal</td>\n",
       "      <td>Deploy web apps anywhere.</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>godotengine / godot</td>\n",
       "      <td>Godot Engine – Multi-platform 2D and 3D game e...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vercel / next.js</td>\n",
       "      <td>The React Framework</td>\n",
       "      <td>Built by</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aiwaves-cn / agents</td>\n",
       "      <td>An Open-source Framework for Autonomous Langua...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>duckduckgo / tracker-radar</td>\n",
       "      <td>Data set of top third party web domains with r...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alamofire / Alamofire</td>\n",
       "      <td>Elegant HTTP Networking in Swift</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>coqui-ai / TTS</td>\n",
       "      <td>🐸💬 - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sczhou / ProPainter</td>\n",
       "      <td>[ICCV 2023] ProPainter: Improving Propagation ...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aras-p / UnityGaussianSplatting</td>\n",
       "      <td>Toy Gaussian Splatting visualization in Unity</td>\n",
       "      <td>Built by</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Snailclimb / JavaGuide</td>\n",
       "      <td>「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WooooDyy / LLM-Agent-Paper-List</td>\n",
       "      <td>The paper list of the 86-page paper \"The Rise ...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>No language specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MunGell / awesome-for-beginners</td>\n",
       "      <td>A list of awesome beginners-friendly projects.</td>\n",
       "      <td>Built by</td>\n",
       "      <td>No language specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fmtlib / fmt</td>\n",
       "      <td>A modern formatting library</td>\n",
       "      <td>Built by</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>meshery / meshery</td>\n",
       "      <td>Meshery, the cloud native manager</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>langchain-ai / langchain</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>Built by</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title  \\\n",
       "0                     hyperdxio / hyperdx   \n",
       "1      williamyang1991 / Rerender_A_Video   \n",
       "2                     NExT-GPT / NExT-GPT   \n",
       "3                       makeplane / plane   \n",
       "4                         grafana / beyla   \n",
       "5     CorentinJ / Real-Time-Voice-Cloning   \n",
       "6                     mastodon / mastodon   \n",
       "7   AntonioErdeljac / next13-lms-platform   \n",
       "8                         TabbyML / tabby   \n",
       "9                        basecamp / kamal   \n",
       "10                    godotengine / godot   \n",
       "11                       vercel / next.js   \n",
       "12               ripienaar / free-for-dev   \n",
       "13                    aiwaves-cn / agents   \n",
       "14             duckduckgo / tracker-radar   \n",
       "15                  Alamofire / Alamofire   \n",
       "16                         coqui-ai / TTS   \n",
       "17                    sczhou / ProPainter   \n",
       "18        aras-p / UnityGaussianSplatting   \n",
       "19                 Snailclimb / JavaGuide   \n",
       "20        WooooDyy / LLM-Agent-Paper-List   \n",
       "21        MunGell / awesome-for-beginners   \n",
       "22                           fmtlib / fmt   \n",
       "23                      meshery / meshery   \n",
       "24               langchain-ai / langchain   \n",
       "\n",
       "                                          Description Contributors Count  \\\n",
       "0   Resolve production issues, fast. An open sourc...           Built by   \n",
       "1   [SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...           Built by   \n",
       "2   Code and models for NExT-GPT: Any-to-Any Multi...           Built by   \n",
       "3   🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...           Built by   \n",
       "4   eBPF-based autoinstrumentation of HTTP and HTT...           Built by   \n",
       "5   Clone a voice in 5 seconds to generate arbitra...           Built by   \n",
       "6   Your self-hosted, globally interconnected micr...           Built by   \n",
       "7                             No description provided           Built by   \n",
       "8                     Self-hosted AI coding assistant           Built by   \n",
       "9                           Deploy web apps anywhere.           Built by   \n",
       "10  Godot Engine – Multi-platform 2D and 3D game e...           Built by   \n",
       "11                                The React Framework           Built by   \n",
       "12  A list of SaaS, PaaS and IaaS offerings that h...           Built by   \n",
       "13  An Open-source Framework for Autonomous Langua...           Built by   \n",
       "14  Data set of top third party web domains with r...           Built by   \n",
       "15                   Elegant HTTP Networking in Swift           Built by   \n",
       "16  🐸💬 - a deep learning toolkit for Text-to-Speec...           Built by   \n",
       "17  [ICCV 2023] ProPainter: Improving Propagation ...           Built by   \n",
       "18      Toy Gaussian Splatting visualization in Unity           Built by   \n",
       "19  「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...           Built by   \n",
       "20  The paper list of the 86-page paper \"The Rise ...           Built by   \n",
       "21     A list of awesome beginners-friendly projects.           Built by   \n",
       "22                        A modern formatting library           Built by   \n",
       "23                  Meshery, the cloud native manager           Built by   \n",
       "24  ⚡ Building applications with LLMs through comp...           Built by   \n",
       "\n",
       "                 Language  \n",
       "0              TypeScript  \n",
       "1        Jupyter Notebook  \n",
       "2                  Python  \n",
       "3              TypeScript  \n",
       "4                       C  \n",
       "5                  Python  \n",
       "6                    Ruby  \n",
       "7              TypeScript  \n",
       "8              TypeScript  \n",
       "9                    Ruby  \n",
       "10                    C++  \n",
       "11             JavaScript  \n",
       "12                   HTML  \n",
       "13                 Python  \n",
       "14             JavaScript  \n",
       "15                  Swift  \n",
       "16                 Python  \n",
       "17                 Python  \n",
       "18                     C#  \n",
       "19                   Java  \n",
       "20  No language specified  \n",
       "21  No language specified  \n",
       "22                    C++  \n",
       "23                     Go  \n",
       "24                 Python  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66874a21",
   "metadata": {},
   "source": [
    "**5.Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:**\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c205549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f7/7l8ws9yx7ybdzmwks1n4tty00000gn/T/ipykernel_1798/184282075.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Song Name Artist Name  \\\n",
      "0                       Vampire           1   \n",
      "1            Paint The Town Red           2   \n",
      "2         I Remember Everything           3   \n",
      "3                      Fast Car           4   \n",
      "4                  Cruel Summer           5   \n",
      "..                          ...         ...   \n",
      "95                      Lagunas          96   \n",
      "96  Sittin' On Top Of The World          97   \n",
      "97                      Rubicon          98   \n",
      "98                          TQM          99   \n",
      "99                     Amargura         100   \n",
      "\n",
      "                          Last Week Rank   Peak Rank  \\\n",
      "0                         Olivia Rodrigo           9   \n",
      "1                               Doja Cat           1   \n",
      "2   Zach Bryan Featuring Kacey Musgraves           2   \n",
      "3                             Luke Combs           3   \n",
      "4                           Taylor Swift           4   \n",
      "..                                   ...         ...   \n",
      "95                            RE-\\nENTRY  RE-\\nENTRY   \n",
      "96                             Burna Boy          86   \n",
      "97                            Peso Pluma          95   \n",
      "98                         Fuerza Regida          89   \n",
      "99                               Karol G          91   \n",
      "\n",
      "               Weeks on Board  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           1  \n",
      "3                           2  \n",
      "4                           3  \n",
      "..                        ...  \n",
      "95  Peso Pluma & Jasiel Nunez  \n",
      "96                         80  \n",
      "97                         63  \n",
      "98                         34  \n",
      "99                         85  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the WebDriver (replace 'path/to/driver' with the actual path to your WebDriver)\n",
    "webdriver_path = \"/Users/siddhant/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "\n",
    "# Get the Billboard Hot 100 webpage\n",
    "driver.get('https://www.billboard.com/charts/hot-100/')\n",
    "\n",
    "# Get the page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Find all the songs details using the elements and classes you provided\n",
    "songs = soup.find_all('div', class_='o-chart-results-list-row-container')\n",
    "\n",
    "# Create empty lists to store song details\n",
    "song_names = []\n",
    "artist_names = []\n",
    "last_week_ranks = []\n",
    "peak_ranks = []\n",
    "weeks_on_boards = []\n",
    "\n",
    "for i, song in enumerate(songs):\n",
    "    try:\n",
    "        song_name = song.find('h3', class_='c-title').get_text(strip=True)\n",
    "    except:\n",
    "        song_name = \"Not found\"\n",
    "    \n",
    "    try:\n",
    "        artist_name = song.find('span', class_='c-label').get_text(strip=True)\n",
    "    except:\n",
    "        artist_name = \"Not found\"\n",
    "    \n",
    "    try:\n",
    "        last_week_rank = song.find_all('span', class_='c-label')[1].get_text(strip=True)\n",
    "    except:\n",
    "        last_week_rank = \"Not found\"\n",
    "    \n",
    "    try:\n",
    "        peak_rank = song.find_all('span', class_='c-label')[2].get_text(strip=True)\n",
    "    except:\n",
    "        peak_rank = \"Not found\"\n",
    "    \n",
    "    try:\n",
    "        weeks_on_board = song.find_all('span', class_='c-label')[3].get_text(strip=True)\n",
    "    except:\n",
    "        weeks_on_board = \"Not found\"\n",
    "    \n",
    "    # Append the details to the respective lists\n",
    "    song_names.append(song_name)\n",
    "    artist_names.append(artist_name)\n",
    "    last_week_ranks.append(last_week_rank)\n",
    "    peak_ranks.append(peak_rank)\n",
    "    weeks_on_boards.append(weeks_on_board)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Song Name\": song_names,\n",
    "    \"Artist Name\": artist_names,\n",
    "    \"Last Week Rank\": last_week_ranks,\n",
    "    \"Peak Rank\": peak_ranks,\n",
    "    \"Weeks on Board\": weeks_on_boards\n",
    "})\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40801f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>1</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>2</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>3</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>4</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>5</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>96</td>\n",
       "      <td>RE-\\nENTRY</td>\n",
       "      <td>RE-\\nENTRY</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>97</td>\n",
       "      <td>Burna Boy</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>98</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQM</td>\n",
       "      <td>99</td>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>100</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song Name Artist Name  \\\n",
       "0                       Vampire           1   \n",
       "1            Paint The Town Red           2   \n",
       "2         I Remember Everything           3   \n",
       "3                      Fast Car           4   \n",
       "4                  Cruel Summer           5   \n",
       "..                          ...         ...   \n",
       "95                      Lagunas          96   \n",
       "96  Sittin' On Top Of The World          97   \n",
       "97                      Rubicon          98   \n",
       "98                          TQM          99   \n",
       "99                     Amargura         100   \n",
       "\n",
       "                          Last Week Rank   Peak Rank  \\\n",
       "0                         Olivia Rodrigo           9   \n",
       "1                               Doja Cat           1   \n",
       "2   Zach Bryan Featuring Kacey Musgraves           2   \n",
       "3                             Luke Combs           3   \n",
       "4                           Taylor Swift           4   \n",
       "..                                   ...         ...   \n",
       "95                            RE-\\nENTRY  RE-\\nENTRY   \n",
       "96                             Burna Boy          86   \n",
       "97                            Peso Pluma          95   \n",
       "98                         Fuerza Regida          89   \n",
       "99                               Karol G          91   \n",
       "\n",
       "               Weeks on Board  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           2  \n",
       "4                           3  \n",
       "..                        ...  \n",
       "95  Peso Pluma & Jasiel Nunez  \n",
       "96                         80  \n",
       "97                         63  \n",
       "98                         34  \n",
       "99                         85  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e07c96",
   "metadata": {},
   "source": [
    "**6) Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare**\n",
    "\n",
    "You have to find the following details\n",
    "\n",
    "Scrape the details of Highest selling novels.\n",
    "\n",
    "A) Book name\n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922593bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the book details\n",
    "table = soup.find('table', {'class': 'in-article sortable'})\n",
    "\n",
    "# Create empty lists to store the details\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "# Iterate through rows of the table, skipping the header row\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    # Check if there are enough columns\n",
    "    if len(columns) >= 5:\n",
    "        book_names.append(columns[1].get_text(strip=True))\n",
    "        author_names.append(columns[2].get_text(strip=True))\n",
    "        volumes_sold.append(columns[3].get_text(strip=True))\n",
    "        publishers.append(columns[4].get_text(strip=True))\n",
    "        genres.append(columns[5].get_text(strip=True))\n",
    "\n",
    "# Create a DataFrame to store the details\n",
    "df = pd.DataFrame({\n",
    "    'Book Name': book_names,\n",
    "    'Author Name': author_names,\n",
    "    'Volumes Sold': volumes_sold,\n",
    "    'Publisher': publishers,\n",
    "    'Genre': genres\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c2d96",
   "metadata": {},
   "source": [
    "**7) Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:**\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time \n",
    "\n",
    "E) Ratings \n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb5e0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Name    Year Span  Runtime Rating     Vote\n",
      "0                  Game of Thrones  (2011–2019)   57 min    9.2  2205255\n",
      "1                  Stranger Things  (2016–2025)   51 min    8.7  1276590\n",
      "2                 The Walking Dead  (2010–2022)   44 min    8.1  1046331\n",
      "3                   13 Reasons Why  (2017–2020)   60 min    7.5   307522\n",
      "4                          The 100  (2014–2020)   43 min    7.6   266600\n",
      "..                             ...          ...      ...    ...      ...\n",
      "95                           Reign  (2013–2017)   42 min    7.5    52755\n",
      "96  A Series of Unfortunate Events  (2017–2019)   50 min    7.8    64814\n",
      "97                  Criminal Minds     (2005– )   42 min    8.1   211128\n",
      "98                          Scream  (2015–2019)   45 min      7    43925\n",
      "99      The Haunting of Hill House       (2018)  572 min    8.6   266246\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the webpage you want to scrape\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lists to store the extracted data\n",
    "    data = []\n",
    "\n",
    "    # Find all TV series elements on the page\n",
    "    tv_series_list = soup.find_all('div', class_='lister-item')\n",
    "\n",
    "    # Iterate through each TV series element\n",
    "    for tv_series in tv_series_list:\n",
    "        # Extract the name\n",
    "        name = tv_series.h3.a.text.strip()\n",
    "\n",
    "        # Extract the year span\n",
    "        year_span = tv_series.find('span', class_='lister-item-year').text.strip()\n",
    "\n",
    "        # Extract the runtime (if available)\n",
    "        runtime_element = tv_series.find('span', class_='runtime')\n",
    "        runtime = runtime_element.text.strip() if runtime_element else \"N/A\"\n",
    "\n",
    "        # Extract the rating (if available)\n",
    "        rating_element = tv_series.find('span', class_='ipl-rating-star__rating')\n",
    "        rating = rating_element.text.strip() if rating_element else \"N/A\"\n",
    "\n",
    "        # Extract the vote (if available)\n",
    "        try:\n",
    "            vote_element = tv_series.find('span', {'name': 'nv'})\n",
    "            vote = vote_element.get('data-value').strip() if vote_element else \"N/A\"\n",
    "        except AttributeError:\n",
    "            vote = \"N/A\"\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append([name, year_span, runtime, rating, vote])\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Year Span', 'Runtime', 'Rating', 'Vote'])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fead3ad",
   "metadata": {},
   "source": [
    "**8) Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:**\n",
    "\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b21204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Dataset Name       Data Type  \\\n",
      "0                                  Iris  Classification   \n",
      "1                         Heart Disease  Classification   \n",
      "2                                 Adult  Classification   \n",
      "3                      Dry Bean Dataset  Classification   \n",
      "4                              Diabetes            null   \n",
      "5                                  Wine  Classification   \n",
      "6  Breast Cancer Wisconsin (Diagnostic)  Classification   \n",
      "7                        Car Evaluation  Classification   \n",
      "8            Rice (Cammeo and Osmancik)  Classification   \n",
      "9                              Mushroom  Classification   \n",
      "\n",
      "                        Task    Attribute Type No of Instances  \\\n",
      "0                    Tabular     150 Instances      4 Features   \n",
      "1               Multivariate     303 Instances     13 Features   \n",
      "2               Multivariate  48.84K Instances     14 Features   \n",
      "3               Multivariate  13.61K Instances     16 Features   \n",
      "4  Multivariate, Time-Series       0 Instances     20 Features   \n",
      "5                    Tabular     178 Instances     13 Features   \n",
      "6               Multivariate     569 Instances     30 Features   \n",
      "7               Multivariate   1.73K Instances      6 Features   \n",
      "8               Multivariate   3.81K Instances      8 Features   \n",
      "9               Multivariate   8.12K Instances     22 Features   \n",
      "\n",
      "  No of Attributes Year  \n",
      "0                        \n",
      "1                        \n",
      "2                        \n",
      "3                        \n",
      "4                        \n",
      "5                        \n",
      "6                        \n",
      "7                        \n",
      "8                        \n",
      "9                        \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL for the UCI Machine Learning Repository datasets page\n",
    "uci_datasets_url = \"https://archive.ics.uci.edu/datasets\"\n",
    "\n",
    "# Send a GET request to the datasets page\n",
    "response = requests.get(uci_datasets_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all dataset entries\n",
    "    dataset_entries = soup.find_all('div', class_='rounded-box bg-base-100')\n",
    "\n",
    "    # Lists to store dataset details\n",
    "    dataset_names = []\n",
    "    data_types = []\n",
    "    tasks = []\n",
    "    attribute_types = []\n",
    "    num_instances = []\n",
    "    num_attributes = []\n",
    "    years = []\n",
    "\n",
    "    # Iterate through each dataset entry\n",
    "    for entry in dataset_entries:\n",
    "        # Extract dataset name\n",
    "        dataset_name = entry.find('h2').text.strip()\n",
    "        dataset_names.append(dataset_name)\n",
    "\n",
    "        # Extract other details if available\n",
    "        details = entry.find_all('span', class_='truncate')\n",
    "\n",
    "        data_type = details[0].text.strip() if len(details) > 0 else \"\"\n",
    "        data_types.append(data_type)\n",
    "\n",
    "        task = details[1].text.strip() if len(details) > 1 else \"\"\n",
    "        tasks.append(task)\n",
    "\n",
    "        attribute_type = details[2].text.strip() if len(details) > 2 else \"\"\n",
    "        attribute_types.append(attribute_type)\n",
    "\n",
    "        num_instance = details[3].text.strip() if len(details) > 3 else \"\"\n",
    "        num_instances.append(num_instance)\n",
    "\n",
    "        num_attribute = details[4].text.strip() if len(details) > 4 else \"\"\n",
    "        num_attributes.append(num_attribute)\n",
    "\n",
    "        # Extract the year from the <td> element\n",
    "        year_element = entry.find('td', text=True, string=True)\n",
    "        year = year_element.text.strip() if year_element else \"\"\n",
    "        years.append(year)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame({\n",
    "        'Dataset Name': dataset_names,\n",
    "        'Data Type': data_types,\n",
    "        'Task': tasks,\n",
    "        'Attribute Type': attribute_types,\n",
    "        'No of Instances': num_instances,\n",
    "        'No of Attributes': num_attributes,\n",
    "        'Year': years\n",
    "    })\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to retrieve the UCI datasets page. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57652278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>null</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>0 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Features</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name       Data Type  \\\n",
       "0                                  Iris  Classification   \n",
       "1                         Heart Disease  Classification   \n",
       "2                                 Adult  Classification   \n",
       "3                      Dry Bean Dataset  Classification   \n",
       "4                              Diabetes            null   \n",
       "5                                  Wine  Classification   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Classification   \n",
       "7                        Car Evaluation  Classification   \n",
       "8            Rice (Cammeo and Osmancik)  Classification   \n",
       "9                              Mushroom  Classification   \n",
       "\n",
       "                        Task    Attribute Type No of Instances  \\\n",
       "0                    Tabular     150 Instances      4 Features   \n",
       "1               Multivariate     303 Instances     13 Features   \n",
       "2               Multivariate  48.84K Instances     14 Features   \n",
       "3               Multivariate  13.61K Instances     16 Features   \n",
       "4  Multivariate, Time-Series       0 Instances     20 Features   \n",
       "5                    Tabular     178 Instances     13 Features   \n",
       "6               Multivariate     569 Instances     30 Features   \n",
       "7               Multivariate   1.73K Instances      6 Features   \n",
       "8               Multivariate   3.81K Instances      8 Features   \n",
       "9               Multivariate   8.12K Instances     22 Features   \n",
       "\n",
       "  No of Attributes Year  \n",
       "0                        \n",
       "1                        \n",
       "2                        \n",
       "3                        \n",
       "4                        \n",
       "5                        \n",
       "6                        \n",
       "7                        \n",
       "8                        \n",
       "9                        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1286e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
